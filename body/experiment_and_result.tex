\hspace{24pt}

This chapter explains the details of the experiments. It includes the use of datasets (Section~\ref{sec:dataset}), the experimental environment (Section~\ref{sec:environment}), the parameters of the NMT model (Section~\ref{sec:parameter}), and the metrics (BLEU score) of the NMT model (Section~\ref{sec:metric}). Lastly, the BLEU scores of the translation system based on different tokenizations and word embeddings are shown in Section~\ref{sec:result}.

\section{Dataset} \label{sec:dataset}

Our datasets are acquired from the Asian Scientific Paper Excerpt Corpus (ASPEC) \cite{nakazawa-etal-2016-aspec} provided by the Japan Science and Technology Agency (JST) and the National Institute of Information and Communications Technology (NICT). ASPEC consists of a Japanese-English corpus (ASPEC-JE) with 3 million parallel sentences and a Japanese-Chinese corpus (ASPEC-JC) with 680,000 pairs.

We have selected ASPEC-JC as the dataset for our zh-ja NMT system, and the structure of the dataset is shown in Table~\ref{tab:aspec-jc}. ASPEC-JC is constructed by manually translating the excerpts of Japanese scientific papers into Chinese. Papers used for translation are derived from the Japan Science and Technology Agency (JST) or the Japan Science and Technology Information Aggregator, Electronic (​J-STAGE).

\vspace{0.4cm}
\begin{table}[h]
    \centering
    \begin{tabularx}{0.7\textwidth}{bbb}\toprule
        Data Type & File Name & Number of sentences \\\midrule
        Train & train.txt & 672,315 \\
        Validation & dev.txt & 2,090 \\
        Validation-Test & devtest.txt & 2,148 \\
        Test & test.txt & 2,107 \\
        \bottomrule
    \end{tabularx}
    \caption{ASPEC-JC dataset}
    \label{tab:aspec-jc}
\end{table}

\section{Environment} \label{sec:environment}

We use PyTorch \footnote{https://pytorch.org/} and PyTorch Lightning \footnote{https://www.pytorchlightning.ai/} \cite{falcon2019pytorch}  as the main framework for constructing the entire NMT model (Section~\ref{sec:lightning}), as well as Weights \& Biases (wandb) \footnote{https://wandb.ai/site} \cite{wandb} for logging models, metrics, and dataflow (Section~\ref{sec:wandb}).

\subsection{PyTorch and PyTorch Lightning} \label{sec:lightning}

PyTorch has been widely used in academic research and production. We use PyTorch as a framework for processing data and designing the components (i.e., encoder, attention, decoder) of RNN and Transformer.

PyTorch-Lightning offers many advantages as a wrapper for PyTorch: Dataflow can be integrated more efficiently in \pythoninline{LightningDataModule}; the main source code, including the components designed by PyTorch, can be integrated into \pythoninline{LightningModule}; using \pythoninline{Trainer} can directly utilize the \pythoninline{LightningDataModule} and \pythoninline{LightningModule}, and help us use the correct engineering code such as gradient update, data transfer between CPU and GPU. In addition, PyTorch-Lightning provides a lot of plugins to simplify research, such as multi-GPU or TPU training, checkpointing and logging of models, implementing 16-bit precision, early stopping, finding learning rate and batch size, etc.

\subsection{Weights and Biases (wandb)} \label{sec:wandb}

Wandb, similar to Tensorboard, is a powerful tool for logging model training and is used by OpenAI \footnote{https://wandb.ai/site/articles/why-experiment-tracking-is-crucial-to-openai}, the company designed GPT-3. Wandb can visualize all training metrics and system performance, record hyperparameters used in the experiments for easy replicating, integrate dataset in the cloud to facilitate the advantages of cross-platform. In the experiments, we use the \pythoninline{WandbLogger} provided by PyTorch-Lightning to integrate wandb and record the experimental results of all models, which will be presented in Section~\ref{sec:result}.

\section{Parameter} \label{sec:parameter}

% 分別在兩種模型的一般參數使用哪些數值。以及 hyperparameter。還有 embedding 解凍。

\section{Metric} \label{sec:metric}

% 我們用 BLEU 做為評分標準。BLEU 是什麼，怎麼算。常見的分數解釋。

\section{Result} \label{sec:result}

% 我們以 WAT 2020 做為標準。什麼是 WAT 2020。他們同樣使用 ASPEC。分別用什麼分詞。分數為多少。

% RNN 的結果，SENTENCEPIECE 結果，LOSS，BLEU。JIEBA JANOME 結果，LOSS，BLEU。

% TRANSFORMER 的結果，SENTENCEPIECE 結果，LOSS，BLEU。JIEBA JANOME 結果，LOSS，BLEU。


% Sample
% \begin{center}\vspace{0.3cm}
%     \begin{tabular}%
%       {l%
%        P{6cm}%
%        P{6cm}%
%        P{6cm}%
%        P{6cm}} \toprule
%     & \multicolumn{2}{c}{Sentencepiece} & \multicolumn{2}{c}{Jieba \& Janome}
%     \\\cmidrule(l){2-3}\cmidrule(l){4-5}
%     & RNN & Transformer & RNN & Transformer\\\midrule
%     w/o Pre-trained emb  & 21.63 & 24.32 & 25.16 & 29.31 \\ \midrule
%     w/ Semantic emb  & 21.66 & 25.72 & 26.71 & 31.23  \\ \midrule
%     w/ Phonetic emb & 21.32 & 23.48 & 26.18 & 30.9 \\\midrule
%     w/ Joint emb & \textbf{22.33} & \textbf{26.44} & \textbf{27.05} & \textbf{32.48}\\
%     \bottomrule
%     \end{tabular}
%     \captionof{table}{\color{Green}BLEU Scores on Sampled Data}
%     \label{table:bleu_sample}
% \end{center}
    

% WAT
% \begin{center}\vspace{0.3cm}
% \begin{tabular}%
%     {l%
%   P{4cm}%
%   P{7cm}%
%   P{4.5cm}%
%   P{4.5cm}%
%   P{4.5cm}} \toprule
%   &WAT2020 & w/o Pre-trained & w/ Semantic & w/ Phonetic & w/ Joint \\\midrule
%   Baseline & 47.00 &&& \\
%   Our Best Model && 52.78 & 52.83 & 53.04 & \textbf{53.13}\\
% \end{tabular}
% \captionof{table}{\color{Green}BLEU Scores on Full Well-Filtered Dataset}
% \label{table:bleu_full}
% \end{center}
