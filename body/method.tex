\hspace{24pt}

method.

\section{Tokenization} \label{sec:tokenization}
\subsection{Tokenizers} \label{sec:tokenizers}
\subsection{SentencePiece} \label{sec:sentencepiece}
\subsection{Jieba} \label{sec:jieba}
\subsection{Janome} \label{sec:janome}

\section{Phonetic Data Extraction} \label{sec:phonetic_data}
\subsection{dragonmapper} \label{sec:dragonmapper}
\subsection{pykakasi} \label{sec:pykakasi}

\section{Embedding} \label{sec:embedding}
\subsection{Word2Vec} \label{sec:word2vec}
\subsection{Phonetic Embedding} \label{sec:phonetic_embedding}
\subsection{Joint Embedding} \label{sec:joint_embedding}

\section{Corpus Filtering} \label{sec:corpus_filtering}

\section{NMT Model} \label{sec:nmt_model}
\subsection{Attention-based GRU encoder-decoder Model} \label{sec:rnn}
\subsection{Transformer} \label{sec:transformer}

% https://bamtercelboo.github.io/2018/05/12/embedding_evaluation/
\section{Embedding Analysis} \label{sec:embedding_analysis}
\subsection{Analogy Reasoning} \label{sec:analogy}
\subsection{Outlier Detection} \label{sec:outlier}
\subsection{Word Similarity} \label{sec:similarity}
\subsection{Homonym and Heteronym} \label{sec:homonym_heteronym}