中文版簡介。手動換行會自動變成下一段文字區塊。

\begin{flushleft}
\mbox{{\bf 關鍵字}： 關鍵字1、關鍵字2、關鍵字3}
\end{flushleft}


% 本篇論文嘗試使用聲音資訊作為文字的額外特徵，並將該特徵應用於中文與日文之間的神經機器翻譯系統當中，旨在透過常規以外的方法如 back translation 或 model ensembling ,以 feature engineering 的方式來加強翻譯系統。 我們提出使用三種不同的分詞方法，以 dragonmapper 及 pykakasi 分別產生中文及日文的聲音資訊，並搭配 word2vec 訓練出兩個單純帶有語意和音意的詞嵌入。我們合併兩者產生帶有語意及音意的合併詞嵌入，並將其投入至兩種知名的 NMT 模型進行訓練與fine-tune。結果表明所有使用了合併詞嵌入進行訓練與fine-tune的模型，其獲得的 BLEU 分數都比其他方法還要更高。我們透過對最好模型的結果進行 case study 發現使用合併詞嵌入翻譯的結果保留了四種property。我們透過對合併詞嵌入與單純包含詞義的嵌入進行分析，結果也表明在四種任務下皆保留原有效果，甚至能超越詞義嵌入，獲得非常正面的反饋。總結，該論文提出的方法能有效提升nmt效能，而且僅使用小型語料庫。對於翻譯結果與詞嵌入我們也展示一系列的分析，得知該詞嵌入確實對於中日文翻譯有明顯的幫助。