Neural machine translation has been gradually improved by the introduction of encoder-decoder networks in recent years. However, the translation between Chinese and Japanese has not been able to achieve the same high quality as that between English and other languages due to the lack of training data and the differences between Eastern and Western languages. This paper attempted to use phonetic information as an additional feature in Chinese and Japanese. After that, features were applied to the neural machine translation system, aiming to enhance the translation quality by feature engineering. This paper first extracted Chinese Bopomofo and Japanese Hiragana as phonetic information from the corpus with three tokenization approaches. Second, the word embeddings with purely semantic and phonetic information are trained using the text information and the phonetic information. Third, we combine both embeddings to produce a joint semantic-phonetic embedding and implement it into two mainstream neural machine translation models for training and further extracting the feature. The results show that the models trained and fine-tuned with joint embeddings have higher BLEU scores than those using semantic or phonetic embeddings only. We also conducted a case study of the translation results. The translations generated by joint embeddings were able to produce correct and even more accurate words, and also preserve the Japanese Katakana and English words, resulting in semantic improvements. 



\begin{flushleft}
\mbox{{\bf Keywords}: Neural Machine Translation, Word Embedding, Feature Engineering, Phoentic Information}
\end{flushleft}

% 實驗另外對合併詞嵌入和單純包含語義的詞嵌入進行四項分析，每項分析皆獲得正面回饋，顯示合併詞嵌入能夠保留乃至超越語義詞嵌入所持有的向量涵義。

% 綜合評估翻譯分數以及詞嵌入分析，我們發現單純使用小型語料庫提取語音資訊作為特徵，便能對中日文的詞向量帶來正面影響，並且進一步使用合併語義及語音的詞嵌入能夠有效提升中日文神經機器翻譯系統的效能。